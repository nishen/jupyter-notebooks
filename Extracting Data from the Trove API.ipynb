{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from Trove APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries\n",
    "\n",
    "At the top, we usually import libraries that we are going to be using. For this example we are using 3 libraries:\n",
    "1. [Pandas](https://pandas.pydata.org/) (https://pandas.pydata.org/)\n",
    "\n",
    "   Pandas is a data analysis library. Even if you are not using it for data analysis, there are lots of tools and utilities that are built in that can prove to be highly beneficial, e.g. it can easily read JSON or CSV data and covert them into Python objects, it can easily output JSON or CSV files from data strutures that you've built/modified as well. Pandas might need to be installed separately unless you've used an installation package like Anaconda.\n",
    "\n",
    "   To install, simply type on a command line:\n",
    "   ```\n",
    "   pip install pandas\n",
    "   ```\n",
    "\n",
    "1. [Requests: HTTP for Humans](http://docs.python-requests.org/en/master/) (http://docs.python-requests.org/en/master/)\n",
    "\n",
    "   Requests is a library that makes working with the web almost trivial. It eliminates much of the code you would otherwise have to write if you were to make HTTP requests and deal with responses. Requests might need to be installed separately unless you've used an installation package like Anaconda.\n",
    "\n",
    "   To install, simply type on a command line:\n",
    "   ```\n",
    "   pip install requests\n",
    "   ```\n",
    "\n",
    "1. [JSON](https://docs.python.org/3/library/json.html) (https://docs.python.org/3/library/json.html)\n",
    "\n",
    "   Unlike the previous two libraries, JSON is built into Python. The JSON library allows Python to convert JSON objects to Python objects and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQKhPTe-k_dW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up some constants and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY=\"erasmus luther\"\n",
    "BASE_URL = \"https://api.trove.nla.gov.au/v2/result?key=[enter TROVE API Key Here]&zone=book&encoding=json&n=100&q=\" + QUERY\n",
    "session = requests.Session()\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions\n",
    "Here we have a function that fetches a page of data for us from Trove. It returns __nextStart__ and __work__. If __nextStart__ is __None__, that means that we have no more pages to fetch. __work__ is a list of all the entries of our search result that are on the fetched page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_data(nextStart = None):\n",
    "    suffix = \"&s=\" + nextStart if nextStart is not None else \"\"\n",
    "    response = session.get(BASE_URL + suffix)\n",
    "    data = response.json()\n",
    "    if \"nextStart\" in data[\"response\"][\"zone\"][0][\"records\"]:\n",
    "        nextStart = data[\"response\"][\"zone\"][0][\"records\"][\"nextStart\"]\n",
    "    else:\n",
    "        nextStart = None\n",
    "    \n",
    "    return nextStart, data[\"response\"][\"zone\"][0][\"records\"][\"work\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch the data\n",
    "Here we fetch the data. We make an initial call to fetch_page_data(). The nextStart parameter of the __fetch_page_data__ function is empty as we are fetching the first page and do not as yet have one. We store the result of the function into two variables:\n",
    "1. __nextStart__: this is the token of the next page in our result set.\n",
    "1. __work__: this sets up the variable for holding the list of our returned results.\n",
    "\n",
    "We then start the loop. If __nextStart__ is None, that means there is no next page and we are done. If __nextStart__ contains a value, then we need to fetch the data on the next page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextStart, work = fetch_page_data()\n",
    "print(\"fetched nextStart: {}, size: {}\".format(None, len(work)))\n",
    "while nextStart is not None:\n",
    "    nextStart, dataset = fetch_page_data(nextStart)\n",
    "    print(\"fetched nextStart: {}, size: {}\".format(nextStart, len(dataset)))\n",
    "    work += dataset\n",
    "\n",
    "print(\"Number of records retrieved: {}\".format(len(work)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data\n",
    "Convert the data we have retrieved into a JSON string, and pass that string to Pandas which can use it to create a DataFrame for us. This is an easy method to create a DataFrame from JSON. We can have a look at the first 5 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huL-dZfuk_da",
    "outputId": "3c7a8333-bb0c-4887-a039-d84b6e5eb8b5"
   },
   "outputs": [],
   "source": [
    "trove_ids = pd.read_json(json.dumps(work)).fillna(\"\")\n",
    "trove_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the data\n",
    "We can now export the data into a CSV file. Pandas again makes this very easy to do. We specify the __to_csv__ method of the DataFrame and provide:\n",
    "1. The name of the CSV file we want to export to.\n",
    "1. _index=False_ tells Pandas not to export the row number of the records.\n",
    "1. _columns_ tells Pandas which columns from the DataFrame we want to export. We do not have to export all. We can also select the order of the columns. In our case we just want the __Trove ID__, __Trove URL__ and __Title__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLTDYX9Sk_di"
   },
   "outputs": [],
   "source": [
    "trove_ids.to_csv(\"trove-data.csv\",\n",
    "                 index=False,\n",
    "                 columns=['id', 'troveUrl', 'title'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Trove_API_testing_loop.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
