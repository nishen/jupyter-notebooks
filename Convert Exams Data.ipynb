{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Python Application\n",
    "## Extracting Course Handbook Information\n",
    "\n",
    "### The Handbook\n",
    "The University Wiki contains lots of intersting information. Within this forest of knowledge, you can find instructions on how to use the University's Course Handbook API.\n",
    "\n",
    "The URL: [Handbook API](https://wiki.mq.edu.au/display/webstrategy/APIs+and+System+Dependencies) (https://wiki.mq.edu.au/display/webstrategy/APIs+and+System+Dependencies)\n",
    "\n",
    "### Our Example\n",
    "For this example we are going to use the Course Handbook API to extract information about Courses. We are going to look at creating a CSV file with the following data:\n",
    "1. Code\n",
    "1. Department\n",
    "1. Faculty\n",
    "1. Name\n",
    "1. Offering\n",
    "1. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Code\n",
    "\n",
    "#### We are going to be breaking down the following Python script:\n",
    "```python\n",
    "import pandas as PD\n",
    "import requests\n",
    "import json\n",
    "\n",
    "data_url = \"http://api.prod.handbook.mq.edu.au/Units/JSON/2019/9f9ef28dea630ae6311cc730207b2b59\"\n",
    "unit_url = \"http://api.prod.handbook.mq.edu.au/Unit/JSON/{}/2019/9f9ef28dea630ae6311cc730207b2b59\"\n",
    "\n",
    "s = requests.Session()\n",
    "r = s.get(data_url)\n",
    "data = PD.read_json(r.text)\n",
    "data.head()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    url = unit_url.format(row[\"Id\"])\n",
    "    r = s.get(url)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        print(\"processing code: {}\".format(row[\"Code\"]))\n",
    "        unit_data = json.loads(r.text)\n",
    "        \n",
    "        if len(unit_data[\"UnitOfferings\"]) == 0:\n",
    "            continue\n",
    "            \n",
    "        if \"code\" in unit_data[\"UnitOfferings\"][0]:\n",
    "            data.at[index, \"Offering\"] = unit_data[\"UnitOfferings\"][0][\"code\"]\n",
    "\n",
    "        if \"description\" in unit_data[\"UnitOfferings\"][0]:\n",
    "            data.at[index, \"Description\"] = unit_data[\"UnitOfferings\"][0][\"description\"]\n",
    "\n",
    "data.fillna(\"\")\n",
    "data.head()\n",
    "data.to_csv(\"unit-codes-2019.csv\",\n",
    "            index=False,\n",
    "            columns=['Code', 'Department', 'Faculty', 'Name', 'Offering', 'Description'])\n",
    "```\n",
    "\n",
    "\n",
    "#### Importing Libraries\n",
    "\n",
    "At the top, we usually import libraries that we are going to be using. For this example we are using 3 libraries:\n",
    "1. [Pandas](https://pandas.pydata.org/) (https://pandas.pydata.org/)\n",
    "\n",
    "   Pandas is a data analysis library. Even if you are not using it for data analysis, there are lots of tools and utilities that are built in that can prove to be highly beneficial, e.g. it can easily read JSON or CSV data and covert them into Python objects, it can easily output JSON or CSV files from data strutures that you've built/modified as well. Pandas might need to be installed separately unless you've used an installation package like Anaconda.\n",
    "\n",
    "   To install, simply type on a command line:\n",
    "   ```\n",
    "   pip install pandas\n",
    "   ```\n",
    "\n",
    "1. [Requests: HTTP for Humans](http://docs.python-requests.org/en/master/) (http://docs.python-requests.org/en/master/)\n",
    "\n",
    "   Requests is a library that makes working with the web almost trivial. It eliminates much of the code you would otherwise have to write if you were to make HTTP requests and deal with responses. Requests might need to be installed separately unless you've used an installation package like Anaconda.\n",
    "\n",
    "   To install, simply type on a command line:\n",
    "   ```\n",
    "   pip install requests\n",
    "   ```\n",
    "\n",
    "1. [JSON](https://docs.python.org/3/library/json.html) (https://docs.python.org/3/library/json.html)\n",
    "\n",
    "   Unlike the previous two libraries, JSON is built into Python. The JSON library allows Python to convert JSON objects to Python objects and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as PD\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up some constants\n",
    "In this next section we set up some constants. Constants are pieces of data that never change.\n",
    "\n",
    "##### Complete Course List: data_url\n",
    "First we setup the URL for where we are going to get our complete list of courses from for 2019. The URL is a copy/paste from the Handbook API page with a change of year to 2019.\n",
    "\n",
    "The resulting dataset should look like the snippet below:\n",
    "```javascript\n",
    "[\n",
    "    {\n",
    "        \"Code\": \"ABEC313\",\n",
    "        \"Department\": \"Department of Educational Studies\",\n",
    "        \"Faculty\": \"Faculty of Human Sciences\",\n",
    "        \"Id\": \"40321\",\n",
    "        \"ModifiedDate\": \"2018-05-28 09:33am\",\n",
    "        \"Name\": \"Early Development 2\",\n",
    "        \"Status\": \"Green\",\n",
    "        \"University\": false,\n",
    "        \"Version\": \"2\"\n",
    "    },\n",
    "    {\n",
    "        \"Code\": \"ABEP330\",\n",
    "        \"Department\": \"Department of Educational Studies\",\n",
    "        \"Faculty\": \"Faculty of Human Sciences\",\n",
    "        \"Id\": \"18\",\n",
    "        \"ModifiedDate\": \"2018-05-28 09:47am\",\n",
    "        \"Name\": \"Program Planning in ATSI Contexts\",\n",
    "        \"Status\": \"Green\",\n",
    "        \"University\": false,\n",
    "        \"Version\": \"2\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "##### Course Details: unit_url\n",
    "The second constant we setup is a URL for obtaining comprehensive data about a specific course. From the snippet above, you can see that each course contains an __Id__. To get the comprehensive data about a course, we will have to use the __unit_url__. However, note the __{}__ in the URL. This is our placeholder for specifying which course we want to get the detailed information about. We need to replace the placeholder with the __Id__ of the course we want to get the detailed information about. This would look like:\n",
    "`http://api.prod.handbook.mq.edu.au/Unit/JSON/40321/2019/9f9ef28dea630ae6311cc730207b2b59`\n",
    "\n",
    "Further down, you will see the following line:\n",
    "\n",
    "```python\n",
    "url = unit_url.format(row[\"Id\"])\n",
    "```\n",
    "\n",
    "This is replacing the placeholder __{}__ with the value of __row[\"Id\"]__. This is part of string formatting. There is a fantastic writeup explaning how this works [here](https://pyformat.info/) (https://pyformat.info/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare constants\n",
    "data_url = \"http://api.prod.handbook.mq.edu.au/Units/JSON/2019/9f9ef28dea630ae6311cc730207b2b59\"\n",
    "unit_url = \"http://api.prod.handbook.mq.edu.au/Unit/JSON/{}/2019/9f9ef28dea630ae6311cc730207b2b59\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching the first dataset - a complete list of courses with a summary of information about each\n",
    "\n",
    "When using the requests library, it is always best to use a session. There are a number of reasons for this, but the simplest is that it is more efficient. The two options are:\n",
    "1. ```python\n",
    "   r = requests.get(url)\n",
    "   ```\n",
    "or\n",
    "2. ```python\n",
    "   session = requests.Session()   \n",
    "   r = session.get(url)\n",
    "   ```\n",
    "The extra line in 2. is well worth it for the speed increase you will get when making repeated calls to a Web API.\n",
    "\n",
    "The `session.get(url)` fetches the data at the url provided. This is roughly the same as typing in a URL in a web browser. The data that comes back is the same data that will be placed in the response object, which we've called __r__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session for efficiency and call it 's'\n",
    "s = requests.Session()\n",
    "\n",
    "# Make a web request and store the response in 'r' after\n",
    "# which 'r' will have the data that we have fetched.\n",
    "r = s.get(data_url)\n",
    "\n",
    "\n",
    "# You can access the data by using 'r.text'. We take the text data,\n",
    "# and get Pandas to read it as JSON (which it is) and then convert\n",
    "# it into a Pandas DataFrame (think Excel Worksheet)\n",
    "\n",
    "data = PD.read_json(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at what we now have in the data frame '__data__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining course details\n",
    "\n",
    "Once we have the list of courses, we want to enrich the data with additional information - namely the offering and description. To do this, we need to make a Web API request for each of the courses that are in our __data__ worksheet. We need to go row by row, and use the __Id__ field to make a Web API request for each course using the __unit_url__.\n",
    "\n",
    "Once we get the data for each course, we need to add it to our __data__ worksheet - simply adding a column with the appropriate data.\n",
    "\n",
    "The __for__ loop allows us to perform tasks across a set of rows of data. Each iteration of the __for__ loop will process the next row of data in sequence. A good explanation of __for__ loops can be found [here](https://www.programiz.com/python-programming/for-loop). Let's examine how this works in this example.\n",
    "\n",
    "The following is often considered a __for each__ style loop. It essentially means that for each of the rows in the DataFrame __data__, extract the index and the row itself and place them into the variables __index__ and __row__ respectively. Then execute the code block directly below it.\n",
    "\n",
    "```python\n",
    "for index, row in data.iterrows()\n",
    "```\n",
    "\n",
    "The __row__ is just a copy of the row in the data frame so changing the row doesn't affect the DataFrame data at all. That's why we also need to use the __index__ when we want to change data in the data frame. The index keeps track of which row we are currently working on. We can change a cell in that row by directly referencing it in the data frame by using:\n",
    "```python\n",
    "data.at[index, \"column name\"] = \"New Value\"\n",
    "```\n",
    "\n",
    "That is basically accessing a specific row and a specific column in the data frame (kind of like a cell in an Excel worksheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each of the rows in the data frame\n",
    "for index, row in data.iterrows():\n",
    "    # build a URL using the unit_url template and replacing the placeholder with the course Id\n",
    "    url = unit_url.format(row[\"Id\"])\n",
    "    # fetch the data\n",
    "    r = s.get(url)\n",
    "    \n",
    "    # 200 means that the fetch was successful and we only proceed if it is 200\n",
    "    if r.status_code == 200:\n",
    "        # output some information for the user running this code\n",
    "        print(\"processing code: {}\".format(row[\"Code\"]))\n",
    "        \n",
    "        # load the response text into a Python object\n",
    "        unit_data = json.loads(r.text)\n",
    "        \n",
    "        # check if we have UnitOfferings in the course details and if not, move on to the next row.\n",
    "        if len(unit_data[\"UnitOfferings\"]) == 0:\n",
    "            continue\n",
    "            \n",
    "        # check if we have a 'code' field in the UnitOfferings and if so\n",
    "        # add it to the data frame row we are working with\n",
    "        if \"code\" in unit_data[\"UnitOfferings\"][0]:\n",
    "            data.at[index, \"Offering\"] = unit_data[\"UnitOfferings\"][0][\"code\"]\n",
    "\n",
    "        # same as above but with description\n",
    "        if \"description\" in unit_data[\"UnitOfferings\"][0]:\n",
    "            data.at[index, \"Description\"] = unit_data[\"UnitOfferings\"][0][\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up the data and checking what we have\n",
    "At this point we should have completed building our dataset. We just need to clean it up a little because when we add new columns to the data frame the default value is a special _missing value_ called __NaN__. We replace all these __NaN__ values with empty strings to make things look a lot neater by calling `data.fillna(\"\")`.\n",
    "\n",
    "Then we display a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the CSV file\n",
    "Again, Pandas makes this trivial. The line below creates a CSV file for us and populates it with our data frame. However, we can also select the columns that we want to output if there are extra ones that we don't want in our output. We pass in a list of column names that we want to output. The `index=False` part tells Pandas that we don't want the row numbers in the output. If we omit this the first column will be row numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"unit-codes-2019.csv\",\n",
    "            index=False,\n",
    "            columns=['Code', 'Department', 'Faculty', 'Name', 'Offering', 'Description'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
